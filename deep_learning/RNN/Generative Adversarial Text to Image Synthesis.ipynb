{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[src](https://arxiv.org/pdf/1605.05396.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network arch\n",
    "* deep convolutional generative adversarial network (DC-GAN) conditioned on text features encoded by a hybrid character-level convolutional recurrent neural network\n",
    "* $G : R^Z x R^T -> R^D$\n",
    "* $D : R^D x R^T -> (0,1)$\n",
    "    * text embedding is available in both gen and disc\n",
    "* The discription embedding $\\phi(t)$ is **concatenated** to the noise Z\n",
    "* $\\hat{x} <- G(z, \\phi(t))$\n",
    "* The discriminator also concats the embedding across the different filter results, then conved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN-CLS - Matching-aware disc\n",
    "* in naive gan, disc separates real from fake\n",
    "* we adjust loss so that we discern 2 types of errors\n",
    "    * unrealistic images from any text\n",
    "    * realistic images from different class\n",
    "* add a third type of input consisting of real images with mismatched text, which the discriminator must learn to score as fake\n",
    "* so 3 types of errors $s_r, s_w, s_f$  which are real image - right text, real image - wrong text and fake image - right text\n",
    "* $L_D = log(s_r) + \\frac{1}{2} (log(1-s_w) + log(1-s_f))$\n",
    "* $L_G = log(s_f)$\n",
    "    * generator needs to try to generate fake images from the right text!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN-INT - learning with manifold interpolation\n",
    "* take normal word embeddings and interpolate them!\n",
    "* $\\min E_{t_1, t_2 \\sim p_{data} }  [log(1 - D(G(z, \\beta t_1 + (1 - \\beta) t_2 )))]  $\n",
    "    * adding this to the generator\n",
    "* Because the interpolated embeddings are synthetic, the discriminator D does not have “real” corresponding image and text pairs to train on. \n",
    "*  However, D learns to predict whether image and text pairs match or not. Thus, if D does a good job at this, then by satisfying D on interpolated text embeddings G can learn to fill in gaps on the data manifold in between training points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code\n",
    "* GAN-CLS https://github.com/reedscot/icml2016/blob/master/main_cls.lua#L320\n",
    "* GAN-INT https://github.com/reedscot/icml2016/blob/master/main_cls_int.lua#L308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
