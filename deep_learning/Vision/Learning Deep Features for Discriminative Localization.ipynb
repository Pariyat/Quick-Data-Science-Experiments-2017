{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[src](https://arxiv.org/pdf/1512.04150.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Activiation Mapping\n",
    "* CAM from global average pooling \n",
    "* global average pooling outputs the spatial average of the feature map of each unit at the last convolutional layer\n",
    "* let $f_k(x,y)$ be the activation of unit k in the last conv layer\n",
    "* $F_k = \\sum_{x,y} f_k (x,y)$\n",
    "* for a given class c, the input to the softmax is $S_c = \\sum_k w_k^c F_k $, where $w_k^c$ indicates the importance of $F_k$ to class c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $M_c(x,y) = \\sum_k w_k^c f_k(x,y)$, where $M_c(x,y)$ indicates the importance of a pixel to a class activation \n",
    "* then we can just upsample $M_c(x,y)$ to the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Average Pooling vs Global Max Pooling\n",
    "* GAP loss encourages the network to identify the extent of the object as compared to GMP which encourages it to identify just one discriminative part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
