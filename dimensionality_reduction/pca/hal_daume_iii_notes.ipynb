{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[booklet](http://ciml.info/dl/v0_99/ciml-v0_99-ch15.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans\n",
    "\n",
    "### KMeans converges\n",
    "\n",
    "* criteria is the RSS: $L(z,u|n) = \\sum_n \\|x_n - u_{z_n}\\|^2 = \\sum_k \\sum_{n:z_n=k} \\|x_n - u_k \\|^2 $\n",
    "* watered-down proof\n",
    "    * KMeans point to cluster reassignment always decreases RSS\n",
    "    * KMeans cluster centroid adjustment always decreases RSS\n",
    "    * therefore RSS always decreases\n",
    "\n",
    "### KMeans initialization\n",
    "\n",
    "* KMeans basically does EM, which converges to local minimas\n",
    "* furthest-first heuristic \n",
    "    * first initialize randomly\n",
    "    * then adjust each centroid to the furthest possible point from it for every centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation as maximizing the direction of maximal variance\n",
    "* project the data onto the vector that points in the direction of maximal variance \n",
    "* if we are projecting onto 1 dim, then we are doing: $max_u \\|Xu\\|^2 $ subj $\\|u\\|^2 - 1 = 0$\n",
    "    * where $X$ is NxD and $u$ is Dx1\n",
    "* take the Lagrangian:\n",
    "    * $$ L(u, \\lambda) = \\|Xu\\|^2 - \\lambda(\\|u\\|^2 - 1) $$\n",
    "    * $$ \\nabla_u = 2X^TXu - 2 \\lambda u$$\n",
    "    * $$ \\lambda u = X^TXu $$\n",
    "    * Notice that this is the eigen decomposition, where $\\lambda$ is a const and $u$ is the eigen vector\n",
    "    * to get a second principal component, repeat, but with the constraint that $u \\cdot v = 0$, the new lagrangian becomes\n",
    "    * $$ L(v, \\lambda) = \\|Xv\\|^2 - \\lambda_1(\\|v\\|^2 - 1) - \\lambda_2 u \\cdot v $$\n",
    "    * $$ \\nabla_v L = 2X^TXv - 2 \\lambda_1 v - \\lambda_2 u  $$\n",
    "    * $$ \\lambda_1 v = (X^TX)v - \\frac{\\lambda2}{2} u  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation as minimizing reconstruction error\n",
    "\n",
    "* the projected data is $Z = Xu$, can be projected back via $Zu^T$\n",
    "* e.g. $u = [1, 0]^T$, $x_1 = [3,3]$, $z_1 = 3$, $z_1 u^T = 3 * [1,0] = [3,0]$, the reconstruction error is $\\| [3,0] - [3,3] \\|^2$\n",
    "* $$ \\| X - Zu^T \\|^2 = \\| X - Xuu^T \\|^2 $$\n",
    "* $$ = (X - Xuu^T)^T (X - Xuu^T) = \\| X \\|^2 - \\| Xuu^T \\|^2 - 2(uu^T) X^TX $$\n",
    "* $$ = \\| X \\|^2 -\\| X \\|^2 - 2 u^TX^TXu  $$\n",
    "* $$ = C - 2u^TX^TXu $$\n",
    "* minimize the above via gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
