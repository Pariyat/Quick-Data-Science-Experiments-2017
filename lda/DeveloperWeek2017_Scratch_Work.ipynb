{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA links\n",
    "\n",
    "* [LDA intro (2 layer hierarchical bayesian model)](http://www.slideshare.net/WayneLee9/lda-oct3-2013)\n",
    "* [Scikit Learn example](http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-topics-extraction-with-nmf-lda-py)\n",
    "* [mechanism & gibbs sampling & mcmc basics](https://www.quora.com/Does-Topic-Modeling-need-a-training-stage-when-using-Gibbs-sampling-And-why-does-it-work/answer/Ivan-Savov)\n",
    "* [EM optimization for LDA](http://obphio.us/pdfs/lda_tutorial.pdf)\n",
    "* [Dirichlet Distribution](http://www.slideshare.net/g33ktalk/machine-learning-meetup-12182013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well i'm not sure about the story nad it did seem biased. What\n",
      "I disagree with is your statement that the U.S. Media is out to\n",
      "ruin Israels reputation. That is rediculous. The U.S. media is\n",
      "the most pro-israeli media in the world. Having lived in Europe\n",
      "I realize that incidences such as the one described in the\n",
      "letter have occured. The U.S. media as a whole seem to try to\n",
      "ignore them. The U.S. is subsidizing Israels existance and the\n",
      "Europeans are not (at least not to the same degree). So I think\n",
      "that might be a reason they report more clearly on the\n",
      "atrocities.\n",
      "\tWhat is a shame is that in Austria, daily reports of\n",
      "the inhuman acts commited by Israeli soldiers and the blessing\n",
      "received from the Government makes some of the Holocaust guilt\n",
      "go away. After all, look how the Jews are treating other races\n",
      "when they got power. It is unfortunate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (data_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1000)\n",
      "  (0, 708)\t1\n",
      "  (0, 410)\t1\n",
      "  (0, 493)\t1\n",
      "  (0, 548)\t1\n",
      "  (0, 130)\t1\n",
      "  (0, 567)\t1\n",
      "  (0, 412)\t1\n",
      "  (0, 750)\t1\n",
      "  (0, 841)\t1\n",
      "  (0, 206)\t1\n",
      "  (0, 764)\t1\n",
      "  (0, 748)\t1\n",
      "  (0, 904)\t1\n",
      "  (0, 923)\t1\n",
      "  (0, 527)\t1\n",
      "  (0, 432)\t1\n",
      "  (0, 988)\t1\n",
      "  (0, 488)\t2\n",
      "  (0, 717)\t1\n",
      "  (0, 587)\t4\n",
      "  (0, 862)\t1\n",
      "  (0, 286)\t1\n",
      "  (0, 867)\t1\n",
      "  (0, 881)\t1\n"
     ]
    }
   ],
   "source": [
    "print (tf.shape)\n",
    "print (tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=10, perp_tol=0.1, random_state=0,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\n",
      "Topic #1:\n",
      "don like just know think ve way use right good going make sure ll point got need really time doesn\n",
      "Topic #2:\n",
      "christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\n",
      "Topic #3:\n",
      "drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\n",
      "Topic #4:\n",
      "hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\n",
      "Topic #5:\n",
      "god people does just good don jesus say israel way life know true fact time law want believe make think\n",
      "Topic #6:\n",
      "55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\n",
      "Topic #7:\n",
      "car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\n",
      "Topic #8:\n",
      "people said did just didn know time like went think children came come don took years say dead told started\n",
      "Topic #9:\n",
      "key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the LDA model has:\n",
    "\n",
    "10 topics, 1000 words, 2000 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1000)\n",
      "[  4.96604155   4.3537397   21.42539886   9.34656164  11.52305328\n",
      "  13.8861695   40.27406664   9.84737644  16.13188767  11.95301712\n",
      "   9.24725729   9.36810397   5.10001764  13.64836908   3.95895035\n",
      "   2.20351083  47.88483728  21.1535831    0.27293177  14.54287686\n",
      "   5.5530001    5.75956702  12.34425041   2.57049698   6.16460343\n",
      "   4.31762237   4.12938934   0.76545744   3.72577593   0.43356217\n",
      "   5.92791121   3.36509377   5.04403287   2.1290783    4.44416027\n",
      "   1.44482564   3.01441175   3.15958896   0.18858835   3.28519136\n",
      "  38.28776415   2.79687305   1.56690784   3.12518011   0.80187587\n",
      "   4.00337725   3.47845026   5.90786908   9.00886246   1.95526998\n",
      "   0.93435688   0.2632052    4.41326525   4.37331326   1.36104572\n",
      "   1.95775214   2.65166035   4.3222133   18.14299357   1.72724557\n",
      "   3.57822658   5.45766768  41.12427674   3.60894078   1.39120378\n",
      "  38.54250212   0.13625848  10.37449816   0.18997826   0.1382722\n",
      "   0.13123498   0.281217     0.91687958  10.21878193   6.09635839\n",
      "  32.68520394   2.56558753   0.13242121   0.21505045   4.54741385\n",
      "   0.12462496   1.79932611   0.22736533   4.29234165   0.16500683\n",
      "   2.21519146   3.60457986   2.84808593   0.31250039  25.5555055\n",
      "  16.52062593  39.10919718   2.25389047  21.99900005   0.37268336\n",
      "   0.14738854   0.12076648   5.8489841    1.47917544   4.32398868]\n"
     ]
    }
   ],
   "source": [
    "print(lda.components_.shape)\n",
    "print(lda.components_[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00344893  0.6285982   0.00344908  0.00344877  0.00344865  0.34381098\n",
      "  0.00344842  0.00344869  0.00344944  0.00344884]\n"
     ]
    }
   ],
   "source": [
    "print(lda.transform(tf)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
