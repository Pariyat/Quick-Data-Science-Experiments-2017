{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[src](http://www.cs.mcgill.ca/~dprecup/courses/ML/Lectures/ml-lecture05.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "* $w <- w + \\alpha \\nabla log L(w) $\n",
    "    * $w <- w + \\alpha \\Phi^T (y - \\hat{y})$\n",
    "* convexity $f(\\lambda a + (1 - \\lambda) b) <= \\lambda f(a) + (1 - \\lambda) f(b)$\n",
    "    * first order $f(a) >= f(b) + \\nabla f(b)^T (a - b)$\n",
    "    * second order - hessian is positive semidefinite $\\frac{d^2f}{d x_i d x_j}$\n",
    "* why logloss is convex \n",
    "    * $-log \\sigma(w^T x)$...\n",
    "    * second order $\\sigma(w^T x) (1 - \\sigma(w^T x)) x x^T$ - this is always greater than 0\n",
    "    * in the 1 dim case, $x^2 \\sigma(wx) (1 - sigma(wx)) = x^2 e^{wx}$, $x^2$ and $e^{wx}$ are both always pos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problistic view of logistic regression\n",
    "* $y_i = 1$ iff $\\hat{y_i} > 0$\n",
    "* $E[y|x] = g^{-1}(w^T x)$\n",
    "\n",
    "### linear regression with features\n",
    "* $J(w) = \\frac{1}{2} (\\Phi w - y)^T (\\Phi w - y) + \\frac{\\lambda}{2} w^T w$\n",
    "* $w = - \\frac{1}{w} \\sum_i (w^T \\phi(x_i) - y_i) \\phi(x_i) = \\sum_i a_i \\phi(x_i) = \\Phi^T a$\n",
    "* use $a$ instead of $\\Phi$\n",
    "* $J(w) = \\frac{1}{2} a^T \\Phi \\Phi^T  \\Phi \\Phi^T a - a^T \\Phi \\Phi^T y + \\frac{1}{2} y^T y + \\frac{\\lambda}{2} a^T \\Phi \\Phi^T  a$\n",
    "* $J(a) = \\frac{1}{2} a^T KK a - a^T  K y + \\frac{1}{2} y^T y + \\frac{\\lambda}{2} a^T K a$\n",
    "* This is quadratic in a, and we can set the gradient to 0 and solve.\n",
    "* $a = (K + \\lambda I_m)^{-1} y $\n",
    "\n",
    "### Quadratic kernel example\n",
    "* $K(x, z) = (x \\dot z)^2$\n",
    "* $K(x, z) = (\\sum_i x_i z_i) (\\sum_j x_j z_j) = \\sum_{i,j \\in {1..n}} x_i z_i x_j z_j = \\sum (x_i x_j) (z_i z_j)$\n",
    "    * we can think of this as a dot product between x and z\n",
    "    * $K(u, v) = (f(u) * f(v))^2 = h(u) * h(v)$\n",
    "        * $h(x) = (f_1(x)^2, \\sqrt{2} f_1(x) f_2(x), f_2(x)^2)$\n",
    "* this is a kernel w/ $\\phi(x) = <x_1^2, x_1 x_2, ...>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
