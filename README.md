# Quick-Data-Science-Experiments-2017

### WIP:
* kernel PCA (projection on linear space)
* discriminative vs generative classifiers (http://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf)
* solve logistic regression via iterated reweighed least square (http://www.win-vector.com/blog/2011/09/the-simpler-derivation-of-logistic-regression/)
* ranking example (https://github.com/Microsoft/LightGBM/tree/master/examples/lambdarank)


### long term:
* bayesian ML McGill (http://www.cs.mcgill.ca/~dprecup/courses/ML/Lectures/)
* berkeley cs194 Russell (https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/)
* berkeley stat 153 (https://www.stat.berkeley.edu/~yuekai/153/)
* ensemble methods (http://www2.islab.ntua.gr/attachments/article/86/Ensemble%20methods%20-%20Zhou.pdf)
* online learning (https://courses.cs.washington.edu/courses/cse599s/14sp/scribes.html)
* UCL RL David Silver (http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
* stat learning theory (http://www.stat.cmu.edu/~ryantibs/statml/)
* cs224 stanford NLP notes (https://github.com/stanfordnlp/cs224n-winter17-notes)
* cs224 stanford social network analysis (http://snap.stanford.edu/class/cs224w-2015/handouts.html)
* UofT cs441 notes (http://www.dgp.toronto.edu/~hertzman/411notes.pdf)
* graphical models (http://www.cs.cmu.edu/~epxing/Class/10708-17/lecture.html)
* fourier transform ee261
* convex optimization (http://www.stat.cmu.edu/~ryantibs/convexopt/)
* gensim notebooks (https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks)
* linear alge interactive book (http://immersivemath.com/ila/index.html)
* kalman filter book (https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python)
* bayesian book (http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
* Udacity notebooks (https://github.com/Ryosuke-Y)
* Udacity courses (https://classroom.udacity.com/me)
* deep learning Montreal summer school (https://mila.umontreal.ca/en/cours/deep-learning-summer-school-2017/slides/)


### to do:
* robust continuous clustering (http://www.pnas.org/content/early/2017/08/28/1700770114.full.pdf)
* constructing 3d models CNN (https://arxiv.org/pdf/1704.00710.pdf)
* ICML field report (https://gmarti.gitlab.io/ml/2017/08/11/ICML-2017-field-reports.html)
* euler's relations between exponential, sine and cosine (http://www.mathcentre.ac.uk/resources/Engineering%20maths%20first%20aid%20kit/latexsource%20and%20diagrams/7_7.pdf)
* dft decomposition
* periodogram - identifying strong frequencies (simulation w/ simple TS)
* periodicity detection (http://www.l3s.de/~anand/tir14/lectures/ws14-tir-foundations-2.pdf)
* deep learning anomaly detection (https://docs.google.com/presentation/d/1HNeSZ0P2WQq0yx9xQXNRb9nkIkcykNUhJvMDwlpJbz4/edit#slide=id.p)
* active learning example (https://github.com/flowersteam/naminggamesal)
* learning to rank using gradient descent (http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf)
* online learning adaptive learning rate (https://courses.cs.washington.edu/courses/cse599s/12sp/scribes/lecture_6.pdf)
* Learning to Generate Reviews and Discovering Sentiment (https://arxiv.org/pdf/1704.01444.pdf)
* pivot tables in excel (https://www.gcflearnfree.org/excel2016/intro-to-pivottables/1/)
* multinomial logistic regression (http://data.princeton.edu/wws509/notes/c6.pdf)
* bayesian interpretation of regularization (http://www.mit.edu/~9.520/spring09/Classes/class15-bayes.pdf)
* subgradient methods (https://www.cs.cmu.edu/~ggordon/10725-F12/slides/06-sg-method.pdf)
* do-rank (https://www.dropbox.com/s/sxg2s2cfh7aezi6/Do-Rank-DCG-Based-Machine-Leanring.pdf?dl=0)
* no R^2 for non-linear models (http://blog.minitab.com/blog/adventures-in-statistics-2/why-is-there-no-r-squared-for-nonlinear-regression)
* theoretical properties of feature hashing (http://www.machinelearning.org/archive/icml2009/papers/407.pdf)
* coordinate descent (https://engineering.jhu.edu/ams/wp-content/uploads/sites/44/2014/08/StephenWrightSlides112014.pdf)
* supervised random walk in social networks (http://cs.stanford.edu/people/jure/pubs/linkpred-wsdm11.pdf)
* loss functions (https://davidrosenberg.github.io/ml2015/docs/3a.loss-functions.pdf)
* minibatch metropolis-hastings (http://bair.berkeley.edu/blog/2017/08/02/minibatch-metropolis-hastings/)
* dl - generative models 
* dl - rl in industry (https://drive.google.com/file/d/0BzUSSMdMszk6bEprTUpCaHRrQ28/view)
* dl - cnn review (https://drive.google.com/file/d/0B6NHiPcsmak1UHBYc0NxNkdGaE0/view)
* dl - automatic differentiation (https://drive.google.com/file/d/0B6NHiPcsmak1ckYxR2hmRGdzdFk/view)
* better communicating table values (https://www.displayr.com/the-magic-trick-that-highlights-significant-results-on-any-table/?utm_source=reddit&utm_medium=machine%20learning&utm_campaign=Trick%20that%20Highlights%20Results%20on%20Table)
* prodigy - active learning kit (https://explosion.ai/blog/prodigy-annotation-tool-active-learning)
* contextualized word vectors (https://einstein.ai/research/learned-in-translation-contextualized-word-vectors)
* svm dual coordinal descent (http://www.stat.ucdavis.edu/~chohsieh/teaching/ECS289G_Fall2015/lecture6.pdf)
* Stochastic Gradient Descent for the Primal L1-SVM Optimization Revisited (http://www.ecmlpkdd2013.org/wp-content/uploads/2013/07/255.pdf)
* primal soft margin svm - gradient descent impl (w261 11.8, constrained to unconstrained optimization, http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/dm2l73iznde7y4f/SVM-Notebook-Linear-Kernel-2015-06-19.ipynb)
* distributed perceptron (http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36266.pdf)
* perceptron review (http://www.cs.cornell.edu/courses/cs678/2003sp/slides/perceptron_4up.pdf)
* boosting with logloss (http://web.mit.edu/marcoct/www/papers/boosting_log_loss.pdf)
* Assessing Retail Employee Risk Through Unsupervised Learning Techniques (https://arxiv.org/pdf/1707.04639.pdf)
* svm w/ RBF look at the alpha weights on the kernel
* image search via multiple color palettes (https://github.com/sergeyk/rayleigh)
* fourier transformation of TS data
* time series classification (http://didawikinf.di.unipi.it/lib/exe/fetch.php/dm/time_series_comparison_2012.pdf)
* clustering time series (http://www1.cs.columbia.edu/~jopa/Papers/PaparrizosSIGMOD2015.pdf)
* notes on loss functions (https://tech.yandex.com/catboost/doc/dg/concepts/loss-functions-docpage/)
* gaussian processes regression (http://www.gaussianprocess.org/gpml/chapters/RW2.pdf)
* exact logistic regression (http://www.cytel.com/hs-fs/hub/1670/file-2416929309-pdf/Pdf/Logistic-Regression---MEHTA-PATEL-Exact-Logistic-Regression-Theory-and-Examples-STATISTICS-IN-MEDICINE-1995.pdf)
* ensemble imbalanced class learning (https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tsmcb09.pdf)
* label propagation graph semisupervised learning tutorial (http://graph-ssl.wdfiles.com/local--files/blog%3A_start/graph_ssl_acl12_tutorial_slides_final.pdf)
* convex optimization for machine learning (https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/optimization/slides.pdf)
* LDA on graphs (https://arxiv.org/abs/1410.4510)
* machine learning techniques for BCI (http://doc.ml.tu-berlin.de/bbci/publications/MueKraDorCurBla04.pdf)
* multilingual embeddings (https://github.com/Babylonpartners/fastText_multilingual)
* contextual bandit langford tut (http://hunch.net/~exploration_learning/main.pdf)
* pinnability pinterest recommendations (https://medium.com/@Pinterest_Engineering/pinnability-machine-learning-in-the-home-feed-64be2074bf60)
* music generation / tensorfow tut (https://github.com/brannondorsey/midi-rnn)
* deepwalk (https://arxiv.org/pdf/1403.6652.pdf)
* diagonosing ML models (https://www.youtube.com/watch?v=0TSvo2hOKo0)
* MNIST PCA first 2 PC vis ESL pg537
* spectural clustering
* bayesian model averaging notes
* bayesian model averaging for regression (https://github.com/timsf/bma)
* kmedoids for strings (spelling correction)
* kMeans T = within + between
* mixed effect for panel data (https://arxiv.org/pdf/1406.5823.pdf)
* predicting similarity matrix via MF or regression
* semisupervised learning survey (http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf)
* density estimation via supervised learning (pg595 ESL)
* association rule tut (http://mhahsler.github.io/arules/)
* Silverman 1986 density estimation survey (https://ned.ipac.caltech.edu/level5/March02/Silverman/paper.pdf)
* lung cancer kaggle sol (https://eliasvansteenkiste.github.io/machine%20learning/lung-cancer-pred/)
* asymmetric gaussian (http://www.iic.ecei.tohoku.ac.jp/~kato/papers/t.kato_spr2002a.pdf)
* causal inference in online systems (http://blog.amitsharma.in/2016/06/27/a-gentle-introduction-to-causal-inference/)
* causal inference observational studies (http://www.cs.nyu.edu/~shalit/slides.pdf)
* kernel fisher LDA (http://www.ics.uci.edu/~welling/classnotes/papers_class/Fisher-LDA.pdf)
* discriminant adaptive nearest neighbors (http://www.cs.uvm.edu/~xwu/kdd/HT-KDD95.pdf)
* transformation invariance in pattern recognition (http://yann.lecun.com/exdb/publis/pdf/simard-00.pdf)
* SVD pseudo inverse proof (http://uspas.fnal.gov/materials/05UCB/6_SVD.pdf)
* SVD UCSD tut (http://mplab.ucsd.edu/wordpress/tutorials/svd.pdf)
* SVD computation (https://www.youtube.com/watch?v=cOUTpqlX-Xs)
* fuzzy SOM NN (http://www.cs.armstrong.edu/wsc11/slides/162.pdf)
* q-learning stock market (http://hallvardnydal.github.io/new_posts/2015-07-21-deep_q/)
* RL MDP simple tut (http://hunch.net/~jl/projects/RL/RLTheoryTutorial.pdf)
* q-learning tut 
* figure out portfolio composition via optimization
* empirical bayesian techniques demo (http://varianceexplained.org/r/simulation-bayes-baseball/)
* one class collaborative filtering (http://www.rongpan.net/publications/pan-oneclasscf.pdf)
* NMF heatmap tut (http://nmf.r-forge.r-project.org/vignettes/heatmaps.pdf)
* metagenes and molecular pattern discovery using matrix factorization (http://www.pnas.org/content/101/12/4164.full.pdf)
* different weighting w/ covariate shift
* hinton diagrams on NMF embeddings
* topic modeling w/ NMF
* boltzmann machines for collaborative filtering (http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf)
* user-based CF, item-based CF - weighted KNN based on correlation
* recommendations content LR approach 
* text summarisation text rank (http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)
* MCMC and Applied Bayesian (http://www.stats.ox.ac.uk/~cholmes/Courses/BDA/bda_mcmc.pdf)
* bayesian technique parameter estimation (http://www4.ncsu.edu/~rsmith/MA797V_S12/MCMC.pdf)
* active portfolio management notes (https://github.com/RJT1990/Active-Portfolio-Management-Notes)
* graph centrality measures (degree, betweeness, closeness, eigenvector, katz, alpha)
* BoW + LSTM sentiment analysis (https://metamind.io/research/learning-when-to-skim-and-when-to-read)
* fb visdom tool (https://github.com/facebookresearch/visdom)
* topic coherence for LDA (http://qpleple.com/topic-coherence-to-evaluate-topic-models/)
* indexing by latent semantic analysis (http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf)
* topological data analysis (http://outlace.com/Topological+Data+Analysis+Tutorial+-+Part+1/)
* gensim summarization (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/summarization_tutorial.ipynb)
* knn images from imagenet embeddings
* Forecasting: principles and practice chapter 7 to 9 (https://www.otexts.org/fpp)
* community detection via Girvan-Newman hierarhical clustering (https://github.com/riteshkasat/Community-Detection-Algorithm)
* LR vs LDA Efron paper (http://pegasus.cc.ucf.edu/~lni/sta6238/Efron1975Efficiency.pdf)
* isomap geodeisc distance
* multidimensional scaling tut (preserving interpoint dist)
* PCA gradient descent solver
* very sparse random projection (http://cseweb.ucsd.edu/~akmenon/VerySparseRPTalk.pdf)
* pyMix mixture models (http://www.pymix.org/pymix/)
* random walk bayesian NN (http://twiecki.github.io/blog/2017/03/14/random-walk-deep-net/)
* EM for data imputation (http://users.stat.umn.edu/~sandy/courses/8053/handouts/Missing.Data.Multiple.Imputation.pdf)
* locally optimized product quantization knn (http://image.ntua.gr/iva/files/lopq.pdf)
* survival analysis via weibull (http://www.stat.columbia.edu/~madigan/W2025/notes/survival.pdf)
* silhouette score review
* spherical k-means (cosine dist) (https://www.jstatsoft.org/article/view/v050i10/v50i10.pdf)
* credit card fraud readup
* recursive autoencoders (http://www.socher.org/index.php/Main/Semi-SupervisedRecursiveAutoencodersForPredictingSentimentDistributions)
* hyperparam tuning - automated machine learning (https://people.eecs.berkeley.edu/~kjamieson/hyperband.html)
* hyperband bandit param opt (https://people.eecs.berkeley.edu/~kjamieson/hyperband.html)
* huffman tree with frequency (https://www.siggraph.org/education/materials/HyperGraph/video/mpeg/mpegfaq/huffman_tutorial.html)
* dual form perceptron
* classifier comparison pitfalls (http://www.cs.bilkent.edu.tr/~guvenir/courses/CS553/On%20Comparing%20Classifiers%20Pitfalls%20to%20Avoid%20and%20a%20recommended%20approach.pdf)
* model assisted sampling (https://github.com/facebookincubator/ml_sampler/blob/master/ml_sampler.pdf)
* prophet forecast library test (https://research.fb.com/prophet-forecasting-at-scale/)
* surprise - bayesian weighting map (http://idl.cs.washington.edu/files/2017-SurpriseMaps-InfoVis.pdf)
* feature engineering notes (https://www.slideshare.net/HJvanVeen/feature-engineering-72376750)
* quantile vs expectile regression (https://www.slideshare.net/charthur/quantile-and-expectile-regression)
* bayesian neural networks 
* MCMC for sampling from posterior ESLR, pg279
* automatic relevance determination
* bass curve (nls w/ 3.12 pg52 IntroTimeSeries Cowpertwait)
* weight elimination (https://papers.nips.cc/paper/323-generalization-by-weight-elimination-with-application-to-forecasting.pdf)
* stochastic gradient boosting notes 
* HOG (CV) (http://mccormickml.com/2013/05/09/hog-person-detector-tutorial/)
* ARCH / GARCH tutorial (http://www.quantatrisk.com/2014/10/23/garch11-model-in-python/)
* radial basis function network (RBFN) (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.312&rep=rep1&type=pdf)
* Gauss-Newton method for non-linear least squares (http://www.seas.ucla.edu/~vandenbe/103/lectures/nlls.pdf)
* sigmoid (W^T X) operates in the linear range if W^{norm} is very small demo
* ICA 
* Missing At Random (MAR test) (http://stats.stackexchange.com/questions/11991/are-misses-in-my-data-distributed-completely-at-random)
* hierarchical mixture of experts (EM & interpretation)
* LDA notes (http://obphio.us/pdfs/lda_tutorial.pdf) 
* STL notes (http://www.wessa.net/download/stl.pdf)
* poisson regression
* FTRL note (http://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf)
* L-BFGS note
* collaborative filtering for ordinal scores (http://www.ijcai.org/Proceedings/13/Papers/449.pdf)
* stacking via CV pedictions (http://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html)
* stochastic search - bumping (XOR decision tree example)
* decision tree missing values (surrogate splits, 9.2.4 ELSL)
* isolation trees (http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)
* factor analysis (http://web.stanford.edu/class/psych253/tutorials/FactorAnalysis.html)
* adaboost vs SVM (https://ucb-mids.s3.amazonaws.com/prod/Machine+Learning/Readings/Week+4/ShortIntroToBoosting.pdf)
* 1NN curse of dim test w/ b-v tradeoff (pg 24, 223)
* LOESS & show that boundary fit is linear
* splines in python, b-splines, thin plate spline
* do bfgs on linear and logistic regression
* linear discriminant analysis (fisher and gaussian derivations)
* quadratic discriminant analysis (https://www.youtube.com/watch?v=JWozRg_X-Vg)
* reduced-rank regression (canonical correlation analysis)
* compressed sensing (http://web.yonsei.ac.kr/nipi/lectureNote/Compressed%20Sensing%20by%20Romberg%20and%20Wakin.pdf)
* steepest descent (https://www.rose-hulman.edu/~bryan/lottamath/steepest.pdf)
* conjugate gradient (http://sep.stanford.edu/data/media/public/oldreports/sep44/44_14.pdf)
* gaussian processes test
* asymptotic normality of MLE (var 2nd deriv)
* gaussian processes for hyperparam optimization
* breaking news prediction on twitter
* multilingual spam filter


### done (long term):
* udacity ud501 ML for Trading

### done:
* label propagation with applications in NLP (https://www.slideshare.net/dav009/label-propagation-semisupervised-learning-with-applications-to-nlp)
* Attention is all you need (https://arxiv.org/pdf/1706.03762.pdf)
* autoregressive async temporal CNN for time series
* ranking with decision trees (http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/materials/Schamoni_boosteddecisiontrees.pdf)
* square vs huberized squared error loss
* gradient boosting review (http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf)
* PLANET decision tree on hadoop (http://www.vldb.org/pvldb/2/vldb09-537.pdf)
* visual proof that NN can compute any function (http://neuralnetworksanddeeplearning.com/chap4.html) 
* tensor multiplication (https://docs.scipy.org/doc/numpy/reference/generated/numpy.tensordot.html)
* faster RCNN (https://arxiv.org/pdf/1506.01497.pdf)
* Revisiting Unreasonable Effectiveness of Data in Deep Learning Era (https://arxiv.org/pdf/1707.02968.pdf)
* time series similarity measures (https://arxiv.org/pdf/1401.3973.pdf)
* linear program python lib (http://benalexkeen.com/linear-programming-with-python-and-pulp/)
* kalman filter algorithm guide (http://web.mit.edu/kirtley/kirtley/binlustuff/literature/control/Kalman%20filter.pdf)
* multiclass / label algorithms (http://scikit-learn.org/stable/modules/multiclass.html)
* regression and causality (http://www.soderbom.net/metrix2/lec3.pdf)
* newton raphson (http://www.sosmath.com/calculus/diff/der07/der07.html)
* gensim LSIs
* chisquare feature selection math
* VAE notes (http://kvfrans.com/variational-autoencoders-explained/)
* take notes on elastic search image search (https://github.com/tuan3w/visual_search)
* graph based recommendation demo (https://medium.com/@Pinterest_Engineering/introducing-pixie-an-advanced-graph-based-recommendation-system-e7b4229b664b)
* bootstrap AB test CI (https://github.com/facebookincubator/bootstrapped)
* beta distribution
* networkX tut (http://snap.stanford.edu/class/cs224w-2011/nx_tutorial/nx_tutorial.pdf)
* LSA tutorial (http://www.engr.uvic.ca/~seng474/svd.pdf)
* panel data R intro (https://www.princeton.edu/~otorres/Panel101R.pdf)
* Simple but tough-to-beat baseline for sentence embedding (https://openreview.net/pdf?id=SyK00v5xx)
* svd matrix inversion
* svd to pca
* random forest variance formula (p*var + (1 - p)/beta *var)
* softmax gating network (https://people.cs.pitt.edu/~milos/courses/cs2750-Spring04/lectures/class22.pdf)
* coclustering methods for recommendations (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.6458&rep=rep1&type=pdf)
* Using asymmetric distributions to improve text classifier probability estimates (https://pdfs.semanticscholar.org/0ad0/d7431ca1b49617e6e5199c0ab5fcec18564f.pdf)
* probability calibration via bayesian binning (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4410090/)
* histogram binning for probability calibration (http://cseweb.ucsd.edu/~elkan/calibrated.pdf)
* arimax python (http://robjhyndman.com/hyndsight/arimax/)
* Facing Imbalanced Data Recommendations for the Use of Performance Metrics (http://www.pitt.edu/~jeffcohn/skew/PID2829477.pdf)
* exploiting time for causal inference (https://dsaber.com/2017/04/02/time-keeps-on-slipping-exploiting-time-for-causal-inference-with-difference-in-differences-and-panel-methods/)
* eigenface (http://www.face-rec.org/algorithms/PCA/jcn.pdf)
* online covariance formula (http://rebcabin.github.io/blog/2013/01/22/covariance-matrices/)
* dataset shift in classification (http://iwann.ugr.es/2011/pdf/InvitedTalk-FHerrera-IWANN11.pdf)
* probability calibration
* Quick Look at SVM blog (https://generalabstractnonsense.com/2017/03/A-quick-look-at-Support-Vector-Machines/)
* temporal regression (decaying RSS)
* brier score for prob calibration (https://timvangelder.com/2015/05/18/brier-score-composition-a-mini-tutorial/)
* lda w/ vw example (http://mlwave.com/tutorial-online-lda-with-vowpal-wabbit/)
* pca principal component vis (w207 class 11 notebook)
* MARS (pyEarth)
* Ljung-Box portmanteau test (http://stat.wharton.upenn.edu/~steele/Courses/956/Resource/TestingNormality/LjungBox.pdf)
* cohen kappa (https://onlinecourses.science.psu.edu/stat509/node/162)
* qr factorization
* skipgram, neg sampling notes (https://arxiv.org/pdf/1310.4546.pdf)
* principal component regression
* apriori algorithm (https://github.com/asaini/Apriori)
* market basket analysis (https://github.com/amitkaps/machine-learning/blob/master/cf_mba/notebook/2.%20Market%20Basket%20Analysis.ipynb)
* classification performance measures (https://www.cs.cornell.edu/courses/cs578/2003fa/performance_measures.pdf)
* kmeans w/ categorical data (http://edu.cs.uni-magdeburg.de/EC/lehre/sommersemester-2013/wissenschaftliches-schreiben-in-der-informatik/publikationen-fuer-studentische-vortraege/kMeansMixedCatNum.pdf)
* partial least square
* ts backtesting (http://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/)
* DBSCAN 
* collabrative filtering with temporal dynamics (http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/p89-koren.pdf)
* euclidean distance weighted by gain ratio, KNN variant
* vector quantization (image reconstruction)
* simpson's paradox (http://corysimon.github.io/articles/simpsons-paradox/)
* eigen decomposition tut
* scalable hierarchical clustering via Spark (http://users.eecs.northwestern.edu/~cji970/pub/cjinBigDataService2015.pdf)
* kernel regression
* deannoymization of netflix dataset (https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf)
* bias-variance example w207_lec_1
* generating rules from decision tree (https://www.mimuw.edu.pl/~son/datamining/DM/6-rules.pdf)
* pandasql tut (https://github.com/yhat/pandasql)
* AIC and BIC for scree plot
* memory based learning (http://www.cs.cornell.edu/courses/cs578/2007fa/CS578_knn_lecture.pdf)
* predicting good probabilities with supervised learning (http://www.datascienceassn.org/sites/default/files/Predicting%20good%20probabilities%20with%20supervised%20learning.pdf)
* gmm classification
* hinton diagrams & for linear reg (http://tonysyu.github.io/mpltools/auto_examples/special/plot_hinton.html)
* levenshtein string clustering (http://stackoverflow.com/questions/21511801/text-clustering-with-levenshtein-distances)
* stitchfix algorithm tour (http://algorithms-tour.stitchfix.com/)
* PRIM bump hunting
* logistic regression training on ratio and weights
* logistic regression covariance of coefficients
* pyFlux presentation (https://github.com/RJT1990/PyData2016-SanFrancisco/blob/master/presentation_final.pdf)
* NMF (how it enforces Non-negativity)
* OAO vs OAA (https://hal.archives-ouvertes.fr/inria-00103955/document)
* perceptron implementation
* quora question nlp tut (https://www.linkedin.com/pulse/duplicate-quora-question-abhishek-thakur)
* naive bayes spam filter
* kernel density classification & kernel smoothing with different local kernels
* recommendations MF, item kNN on latent space
* affinity propagation clustering (http://www.igi.tugraz.at/lehre/MLA/WS07/MLA_AffinityPropagation.pdf)
* pagerank impl (https://github.com/ashkonf/PageRank)
* pagerank math
* bayes optimal error rate (http://stats.stackexchange.com/questions/4949/calculating-the-error-of-bayes-classifier-analytically)
* decision tree imple
* ch15 notes Hal Daume III unsupervised learning (KMeans + PCA)
* permutation importance (decision tree)
* ranking item recommendations for a user from matrix factorization
* hierarchical clustering dendrogram analysis
* imputation in scikit-learn (http://scikit-learn.org/stable/auto_examples/missing_values.html#sphx-glr-auto-examples-missing-values-py)
* twitter sentiment vs stock markers (https://arxiv.org/pdf/1010.3003.pdf)
* FTRL math (https://courses.cs.washington.edu/courses/cse599s/12sp/scribes/Lecture8.pdf)
* granger causality time series (http://www-bcf.usc.edu/~liu32/cause.pdf)

===

### potential tuts:
* different types of FMs
* Spark AllReduce
* lessons from Quora ML
* notes like [this](http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf)
