# Quick-Data-Science-Experiments-2017


### current:
* solve logistic regression via iterated reweighed least square (http://www.win-vector.com/blog/2011/09/the-simpler-derivation-of-logistic-regression/)
* naive bayes spam filter
* robust regression
* ranking example (https://github.com/Microsoft/LightGBM/tree/master/examples/lambdarank)


### to do:
* kernel density classification
* splines in python, b-splines?
* do bfgs on linear and logistic regression
* perceptron implementation
* prob calibration with covariate shift
* linear discriminant analysis (fisher and gaussian derivations)
* quadratic discriminant analysis
* reduced-rank regression (canonical correlation analysis)
* compressed sensing (http://web.yonsei.ac.kr/nipi/lectureNote/Compressed%20Sensing%20by%20Romberg%20and%20Wakin.pdf)
* steepest descent (https://www.rose-hulman.edu/~bryan/lottamath/steepest.pdf)
* conjugate gradient (http://sep.stanford.edu/data/media/public/oldreports/sep44/44_14.pdf)
* svd to pca
* gaussian processes test
* asymptotic normality of MLE (var 2nd deriv)
* bayesian model averaging
* large scale L1 feature selection with Vowpal Wabbit
* churn prediction example
* gaussian processes for hyperparam optimization
* breaking news prediction on twitter


### done:
* probability calibration
* qr factorization
* principal component regression
* partial least square
* eigen decomposition tut
* bias-variance example w207_lec_1
* logistic regression training on ratio and weights
* logistic regression covariance of coefficients
