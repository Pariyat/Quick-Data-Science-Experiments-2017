# Quick-Data-Science-Experiments-2017

### WIP:
* kernel PCA (projection on linear space)
* discriminative vs generative classifiers (http://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf)
* solve logistic regression via iterated reweighed least square (http://www.win-vector.com/blog/2011/09/the-simpler-derivation-of-logistic-regression/)
* ranking example (https://github.com/Microsoft/LightGBM/tree/master/examples/lambdarank)
* WTTE RNN churn modeling (https://ragulpr.github.io/2016/12/22/WTTE-RNN-Hackless-churn-modeling/)



### long term:
* scikit-learn autoexamples
* gensim notebooks (https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks)
* cs224 NLP notes (https://github.com/stanfordnlp/cs224n-winter17-notes)
* exercises from Scientific Programming w/ Python (http://scipython.com/book/)
* ggplot tut 
* bokeh tut (http://nbviewer.jupyter.org/github/bokeh/bokeh-notebooks/blob/master/tutorial/00%20-%20intro.ipynb)
* berkeley stat 153 (https://www.stat.berkeley.edu/~yuekai/153/)


### to do:
* pca principal component vis (w207 class 11 notebook)
* topic coherence for LDA (http://qpleple.com/topic-coherence-to-evaluate-topic-models/)
* indexing by latent semantic analysis (http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf)
* stitchfix algorithm tour (http://algorithms-tour.stitchfix.com/)
* topological data analysis (http://outlace.com/Topological+Data+Analysis+Tutorial+-+Part+1/)
* gensim summarization (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/summarization_tutorial.ipynb)
* simpson's paradox (http://corysimon.github.io/articles/simpsons-paradox/)
* knn images from imagenet embeddings
* levenshtein string clustering (http://stackoverflow.com/questions/21511801/text-clustering-with-levenshtein-distances)
* Forecasting: principles and practice chapter 7 to 9 (https://www.otexts.org/fpp)
* community detection via Girvan-Newman hierarhical clustering (https://github.com/riteshkasat/Community-Detection-Algorithm)
* LR vs LDA Efron paper (http://pegasus.cc.ucf.edu/~lni/sta6238/Efron1975Efficiency.pdf)
* isomap geodeisc distance + mds
* multidimensional scaling tut (preserving interpoint dist)
* PCA gradient descent solver
* very sparse random projection (http://cseweb.ucsd.edu/~akmenon/VerySparseRPTalk.pdf)
* pyMix mixture models (http://www.pymix.org/pymix/)
* AIC and BIC for scree plot
* random walk bayesian NN (http://twiecki.github.io/blog/2017/03/14/random-walk-deep-net/)
* EM for data imputation (http://users.stat.umn.edu/~sandy/courses/8053/handouts/Missing.Data.Multiple.Imputation.pdf)
* locally optimized product quantization knn (http://image.ntua.gr/iva/files/lopq.pdf)
* take notes on elastic search image search (https://github.com/tuan3w/visual_search)
* ts backtesting (http://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/)
* survival analysis via weibull (http://www.stat.columbia.edu/~madigan/W2025/notes/survival.pdf)
* hierarchical clustering dendrogram analysis
* DBSCAN 
* silhouette score review
* spherical k-means (cosine dist) (https://www.jstatsoft.org/article/view/v050i10/v50i10.pdf)
* credit card fraud readup
* recursive autoencoders (http://www.socher.org/index.php/Main/Semi-SupervisedRecursiveAutoencodersForPredictingSentimentDistributions)
* hyperparam tuning - automated machine learning (https://people.eecs.berkeley.edu/~kjamieson/hyperband.html)
* hyperband bandit param opt (https://people.eecs.berkeley.edu/~kjamieson/hyperband.html)
* lda w/ vw example (http://mlwave.com/tutorial-online-lda-with-vowpal-wabbit/)
* huffman tree with frequency (https://www.siggraph.org/education/materials/HyperGraph/video/mpeg/mpegfaq/huffman_tutorial.html)
* dual form perceptron
* kernel regression
* classifier comparison pitfalls (http://www.cs.bilkent.edu.tr/~guvenir/courses/CS553/On%20Comparing%20Classifiers%20Pitfalls%20to%20Avoid%20and%20a%20recommended%20approach.pdf)
* bayes optimal error rate (http://stats.stackexchange.com/questions/4949/calculating-the-error-of-bayes-classifier-analytically)
* precision recall break even point (http://www.nssl.noaa.gov/users/brooks/public_html/feda/papers/ProvostandFawcettKDD-97.pdf)
* euclidean distance weighted by gain ratio, KNN variant
* classification performance measures (https://www.cs.cornell.edu/courses/cs578/2003fa/performance_measures.pdf)
* memory based learning (http://www.cs.cornell.edu/courses/cs578/2007fa/CS578_knn_lecture.pdf)
* model assisted sampling (https://github.com/facebookincubator/ml_sampler/blob/master/ml_sampler.pdf)
* bootstrap AB test CI (https://github.com/facebookincubator/bootstrapped)
* prophet forecast library test (https://research.fb.com/prophet-forecasting-at-scale/)
* surprise - bayesian weighting map (http://idl.cs.washington.edu/files/2017-SurpriseMaps-InfoVis.pdf)
* feature engineering notes (https://www.slideshare.net/HJvanVeen/feature-engineering-72376750)
* quantile vs expectile regression (https://www.slideshare.net/charthur/quantile-and-expectile-regression)
* bayesian neural networks 
* MCMC for sampling ftom posterior ESLR, pg279
* automatic relevance determination
* bass curve (nls w/ 3.12 pg52 IntroTimeSeries Cowpertwait)
* weight elimination (https://papers.nips.cc/paper/323-generalization-by-weight-elimination-with-application-to-forecasting.pdf)
* hinton diagrams & for linear reg (http://tonysyu.github.io/mpltools/auto_examples/special/plot_hinton.html)
* levelplots interpretation
* stochastic gradient boosting notes 
* HOG (CV) (http://mccormickml.com/2013/05/09/hog-person-detector-tutorial/)
* ARCH / GARCH tutorial (http://www.quantatrisk.com/2014/10/23/garch11-model-in-python/)
* radial basis function network (RBFN) (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.312&rep=rep1&type=pdf)
* Gauss-Newton method for non-linear least squares (http://www.seas.ucla.edu/~vandenbe/103/lectures/nlls.pdf)
* sigmoid (W^T X) operates in the linear range if W^{norm} is very small demo
* ICA 
* semisupervised learning survey (http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf)
* square vs huberized squared error loss
* Missing At Random (MAR test) (http://stats.stackexchange.com/questions/11991/are-misses-in-my-data-distributed-completely-at-random)
* PRIM bump hunting
* MARS (pyEarth)
* hierarchical mixture of experts (EM & interpretation)
* LDA notes (http://obphio.us/pdfs/lda_tutorial.pdf) 
* STL notes
* poisson regression
* FTRL note (http://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf)
* L-BFGS note
* NMF (how it enforces Non-negativity)
* collaborative filtering for ordinal scores (http://www.ijcai.org/Proceedings/13/Papers/449.pdf)
* coclustering methods (recommendations)
* stacking via CV pedictions (http://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html)
* stochastic search - bumping (XOR decision tree example)
* decision tree missing values (surrogate splits, 9.2.4 ELSL)
* isolation trees (http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)
* random forest variance formula (p*var + (1 - p)/beta *var
* factor analysis (http://web.stanford.edu/class/psych253/tutorials/FactorAnalysis.html)
* adaboost vs SVM (https://ucb-mids.s3.amazonaws.com/prod/Machine+Learning/Readings/Week+4/ShortIntroToBoosting.pdf)
* bayesian model averaging & BIC
* kernel density classification & kernel smoothing with different local kernels
* rbf regression & gmm classification
* 1NN curse of dim test w/ b-v tradeoff (pg 24, 223)
* LOESS & show that boundary fit is linear
* splines in python, b-splines, thin plate spline
* do bfgs on linear and logistic regression
* prob calibration with covariate shift
* linear discriminant analysis (fisher and gaussian derivations)
* quadratic discriminant analysis (https://www.youtube.com/watch?v=JWozRg_X-Vg)
* reduced-rank regression (canonical correlation analysis)
* compressed sensing (http://web.yonsei.ac.kr/nipi/lectureNote/Compressed%20Sensing%20by%20Romberg%20and%20Wakin.pdf)
* steepest descent (https://www.rose-hulman.edu/~bryan/lottamath/steepest.pdf)
* conjugate gradient (http://sep.stanford.edu/data/media/public/oldreports/sep44/44_14.pdf)
* svd to pca
* gaussian processes test
* asymptotic normality of MLE (var 2nd deriv)
* large scale L1 feature selection with Vowpal Wabbit
* gaussian processes for hyperparam optimization
* breaking news prediction on twitter
* multilingual spam filter


### done:
* Facing Imbalanced Data Recommendations for the Use of Performance Metrics (http://www.pitt.edu/~jeffcohn/skew/PID2829477.pdf)
* eigenface (http://www.face-rec.org/algorithms/PCA/jcn.pdf)
* online covariance formula (http://rebcabin.github.io/blog/2013/01/22/covariance-matrices/)
* dataset shift in classification (http://iwann.ugr.es/2011/pdf/InvitedTalk-FHerrera-IWANN11.pdf)
* probability calibration
* temporal regression (decaying RSS)
* Ljung-Box portmanteau test (http://stat.wharton.upenn.edu/~steele/Courses/956/Resource/TestingNormality/LjungBox.pdf)
* cohen kappa (https://onlinecourses.science.psu.edu/stat509/node/162)
* qr factorization
* skipgram, neg sampling notes (https://arxiv.org/pdf/1310.4546.pdf)
* principal component regression
* kmeans w/ categorical data (http://edu.cs.uni-magdeburg.de/EC/lehre/sommersemester-2013/wissenschaftliches-schreiben-in-der-informatik/publikationen-fuer-studentische-vortraege/kMeansMixedCatNum.pdf)
* partial least square
* vector quantization (image reconstruction)
* eigen decomposition tut
* scalable hierarchical clustering via Spark (http://users.eecs.northwestern.edu/~cji970/pub/cjinBigDataService2015.pdf)
* bias-variance example w207_lec_1
* generating rules from decision tree (https://www.mimuw.edu.pl/~son/datamining/DM/6-rules.pdf)
* pandasql tut (https://github.com/yhat/pandasql)
* logistic regression training on ratio and weights
* logistic regression covariance of coefficients
* OAO vs OAA (https://hal.archives-ouvertes.fr/inria-00103955/document)
* perceptron implementation
* naive bayes spam filter
* decision tree imple
* ch15 notes Hal Daume III unsupervised learning (KMeans + PCA)
* permutation importance (decision tree)
* ranking item recommendations for a user from matrix factorization
* imputation in scikit-learn (http://scikit-learn.org/stable/auto_examples/missing_values.html#sphx-glr-auto-examples-missing-values-py)

===

### potential tuts:
* different types of FMs
* Spark AllReduce
* lessons from Quora ML
* notes like [this](http://demo.clab.cs.cmu.edu/cdyer/nce_notes.pdf)
